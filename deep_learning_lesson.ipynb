{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37544e3b",
   "metadata": {},
   "source": [
    "# MNIST Dataset using TensorFlow\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c43e1a",
   "metadata": {},
   "source": [
    "# Run the following commands in your terminal\n",
    "- conda install -c apple tensorflow-deps\n",
    "- python -m pip install tensorflow-macos\n",
    "- pip install tensorflow-datasets\n",
    "- NOTE: DO NOT INSTALL THIS ON M1 MAC! As of Jan 17 2023 \"python -m pip install tensorflow-metal\" will not work for M1 Mac GPU Acceleration. Due to this the model will be trained on the CPU. DO NOT INSTALL THIS ON M1 MAC!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f82bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6ddc6b",
   "metadata": {},
   "source": [
    "### Scaling data(optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68924a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast the records into float values\n",
    "#x_train = x_train.astype('float32')\n",
    "#x_test = x_test.astype('float32')\n",
    "  \n",
    "#normalize image pixel values by dividing by 255\n",
    "#normal_scale = 255\n",
    "#x_train /= normal_scale\n",
    "#x_test /= normal_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e7949",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#peak at the data\n",
    "#each index is one observation(image) represented in a multi-dimensional numpy array\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d5350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#each individual array is one numpy array representing one row of pixels\n",
    "x_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1f7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how our data is split\n",
    "print(\"Feature matrix:\", x_train.shape)\n",
    "print(\"Target matrix:\", x_test.shape)\n",
    "print(\"Feature matrix:\", y_train.shape)\n",
    "print(\"Target matrix:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d94fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a look at some observations\n",
    "fig, ax = plt.subplots(10, 10)\n",
    "k = 0\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        ax[i][j].imshow(x_train[k].reshape(28, 28), \n",
    "                        aspect='auto')\n",
    "        k += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a311a85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining our mode\n",
    "#sequential = feed forward network\n",
    "model = Sequential([\n",
    "    \n",
    "    # reshape 28 row * 28 column data to 28*28 rows\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    \n",
    "      # dense(hidden) layer 1\n",
    "    Dense(256, activation='sigmoid'),  \n",
    "    \n",
    "    # dense(hidden) layer 2\n",
    "    Dense(128, activation='sigmoid'), \n",
    "    \n",
    "      # output layer\n",
    "    Dense(10, activation='sigmoid'),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to \"compile\" our model by specifying our optimizer, how to calculate our cost function(loss)\n",
    "#and what our metric is\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe636b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we train our model like any other with a x_train and y_train\n",
    "#epochs is how many times we update our weights\n",
    "#batch size is how many observation to look at while preforming SGD\n",
    "#we can define a validation split between our epochs to determine how well it does with out of sample data\n",
    "model.fit(x_train, y_train, epochs=10, \n",
    "          batch_size=2000, \n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a526abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final model score against our test data\n",
    "results = model.evaluate(x_test,  y_test, verbose = 0)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e81522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
